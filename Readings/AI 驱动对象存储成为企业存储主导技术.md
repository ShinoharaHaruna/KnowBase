---
title: AI 驱动对象存储成为企业存储主导技术
author: Andy730
date created: 2024-12-24T15:27:00
category: 技术趋势
tags:
  - "#对象存储"
  - "#AI"
  - "#技术趋势"
  - "#数据管理"
  - "#云计算"
url:
  - https://mp.weixin.qq.com/s/PfMCnRZ0ZCF3IdN_0gDdaw
description: 这份文档探讨了AI技术对企业存储的影响，特别强调对象存储在AI时代的主导地位。随着AI，尤其是生成式AI的发展，对存储性能和规模的需求不断增加，对象存储因其优异的性能、扩展性和安全性成为首选。当前，超过70%的云原生数据已存于对象存储中，预计两年内将增至75%。尽管公有云在AI工作负载中占据优势，混合云的使用也在增长，主要出于对成本和数据控制的考虑。文档还指出，企业在AI应用中面临的主要挑战包括安全性、数据治理和高成本，促使更多企业转向私有云以降低开支。总体而言，对象存储凭借其支持大规模数据处理和AI模型训练的能力，继续在AI驱动的存储转型中发挥关键作用。
status: 已读完
---

## 关键洞

1. **AI 驱动存储转型**：AI 的需求推动了对象存储成为企业存储的主导技术，尤其是对于大规模数据处理和并行计算工作负载，尤其是在 AI 模型训练、推理及数据湖仓存储中。
2. **对象存储的普及**：超过 70% 的云原生数据已存储在对象存储中，预计两年内这一比例将增至 75%。对象存储因其性能、扩展性、安全性等特点，成为支持 AI 工作负载的首选技术。
3. **AI 工作负载对存储的需求**：AI（尤其是生成式 AI）对存储性能和规模提出更高要求，对象存储能满足这些需求，支持大规模数据集、模型训练、生成式 AI 向量数据库等。
4. **AI 挑战**：尽管 AI 发展迅速，企业面临的主要挑战包括安全性、数据治理和高成本，尤其是在公有云中运行 AI 时，成本和性能成为关键考量因素。
5. **云与私有云的平衡**：虽然公有云在 AI 工作负载中占主导地位，但混合云部署日益增多，企业对私有云和公有云的结合使用感兴趣，尤其是在面对成本和数据控制需求时。
6. **未来存储发展**：随着数据存储规模和访问需求的不断增长，对象存储在性能、扩展性、安全性及简便性上的优势将持续推动其在 AI 时代的应用。

![OSSusage](OSSusage.webp)

![ChallengesOfOSSinAI](ChallengesOfOSSinAI.webp)

数据存储领域正经历一场深刻变革。

AI 从根本上重塑了我们对数据存储规模、性能及大规模并行处理能力的需求。以往，企业和组织多依赖于传统的 SAN/NAS 架构。然而，随着非结构化数据呈指数级增长，规模已至 PB 级别，一个事实愈发清晰：对象存储已成为企业存储需求的主导技术。

报告中最明确的发现是，企业有多少比例的数据存储在对象存储中。IT 领导者指出，企业超过 70% 的云原生数据存于对象存储中。这一比例颇为惊人，且预计将持续增长。

> 调查图片就不摆了（

展望未来，企业领导者计划加大投资力度，预测两年后，75% 的云原生数据将存储于对象存储中。AI 的发展以及面向 AI 的数据湖仓（Data Lakehouse）的兴起，将在未来几年进一步推动这一趋势，使对象存储成为未来可预见时间内的标志性存储技术。

## AI 的必要性

鉴于对象存储在企业中占据如此重要的地位，我们向 IT 领导者询问了推动采用对象存储的动因以及哪些工作负载利用了这些对象存储。

前三大回答是相互关联的概念：AI 项目需要大规模性能。在 1PB 规模下实现高性能相对容易，但在 100PB 规模下保持高性能则完全不同。而这正是 AI 工作负载的核心需求。

由于这一问题的重要性，我们从稍微不同的角度再次提出，得到的答案基本一致。

## 哪些工作负载使用对象存储？

- 高级分析（Advanced Analytics），例如 Spark、Presto/Trino、SQL Server 和 Snowflake（54%）。

这类工作负载，如网络安全异常检测，需要持续的大规模吞吐能力以支持高速分析。大多数供应商建议将架构分割为更小的命名空间，因为它们无法处理单一的超大规模（Exascale）命名空间。然而，这种工作负载正是对象存储解决方案的典型应用场景。

- AI 模型训练和推理（AI Model Training and Inference），包括 LLM 和 RAG（51%）。

AI 需要性能和规模，而对象存储能够满足这一需求。因此，未来对象存储将继续占据优势。

- 数据湖仓存储（Data Lakehouse Storage）（44%）。

数据湖仓完全基于对象存储构建，71% 的受访者表示他们已经部署或计划在未来 12 个月内构建数据湖仓。这表明数据湖仓已成为对象存储的优先应用方向，并可能进一步增长。

> 数据湖仓（Data Lakehouse）是一种结合了数据湖和数据仓库优势的架构。它旨在解决传统数据湖和数据仓库各自的局限性，提供统一的存储和分析平台。
>
> 特点
>
> 1. **统一存储**：支持结构化和非结构化数据的存储，利用数据湖的灵活性。
> 2. **高效查询**：结合数据仓库的性能优化，支持 SQL 查询和实时分析。
> 3. **数据治理**：提供数据管理和治理工具，确保数据质量和安全。
> 4. **灵活性**：支持多种数据格式和数据源，满足不同的分析需求。
> 5. **成本效益**：利用云存储的低成本和弹性，减少存储和计算成本。
>
> 优势
>
> - **简化架构**：减少了数据复制和移动的需求，降低了复杂性。
> - **实时分析**：能够快速处理和分析数据，支持实时决策。
> - **扩展性**：可以轻松扩展以处理大规模数据集。
>
> 应用场景
>
> - **商业智能**：提供快速的数据查询和报告生成。
> - **机器学习**：支持大规模数据集的训练和预测。
> - **数据科学**：为数据科学家提供灵活的数据操作和分析环境。
>
> 这种架构适合需要同时处理批处理和流处理的企业，帮助他们更高效地管理和分析数据。

以上三种使用场景都具有巨大的行业变革潜力。然而，从生成式 AI 的迅速崛起到传统 AI 形式的持续重要性，这些 AI 工作负载目前是推动对象存储新采用的最强动力。

现代对象存储具备支持 AI/ML 等高要求工作负载所需的性能、可扩展性和安全性等特性。因此，==开发者选择对象存储来保存各种数据集，用于训练模型、微调模型，以及构建生成式 AI 的向量数据库==。随着 AI 应用场景的不断拓展，数据集、模型和向量数据库的规模也将随之增长。

我们向 IT 领导者询问了其组织用于 AI 分析的训练数据集类型，结果涵盖了从地理空间数据到应用程序数据的 10 种不同数据类型。其中，应用程序数据的重要性尤为突出。虽然这一类别较为宽泛，但表明 IT 领导者正在尝试从核心业务数据中挖掘更多价值。

值得注意的是，在生成式 AI（GenAI）领域，基于云托管 LLM（Cloud Hosted LLM）和自托管 LLM（Self Hosted LLM）的选择几乎不相上下。尽管目前公有云略占优势，但这可能预示着企业对关键工作负载部署位置的考量正在发生转变。

另一个有趣的发现是，传统 AI 依然保持着强劲的生命力。企业并未因生成式 AI 的兴起而忽视传统 AI。大量数据类型仍被用于训练传统 AI 模型，这表明这些工作负载的重要性依然存在。

而自定义语料库（Custom Corpus）的排名相对较低，这可能暗示存在一定的挑战。在训练数据集和工作负载相关的问题中，受访者对自定义语料库及基于自定义语料库的 RAG 的选择均低于其他选项。==这表明企业在构建自定义语料库所需的基础设施、工程和实验方面可能面临困难==。

在具体的 AI 应用场景方面，IT 领导者的视野相对广泛。从排名最高的威胁检测到排名最低的物联网遥测，各选项之间的差距较小。这表明数据基础设施团队正在积极探索如何为组织创造更大的业务价值。

AI 的发展并非一帆风顺。在接受调查的组织中，超过 96% 已经开始运行 AI/ML 工作负载，并逐渐发现了其中的痛点。我们进一步向 IT 领导者提出了以下问题：

受访者报告指出，AI 面临的三大主要挑战是：

1. 安全性和隐私问题（44%）

这一挑战在 IT 领导者中备受关注。AI 模型在数据处理和保护方面存在诸多不确定性，企业希望对数据拥有绝对控制权。他们担心公有云提供商的数据泄露问题，不愿因此丧失竞争优势。在 AI 应用中，企业倾向于避免将数据发送至主流 LLM（Large Language Models，大型语言模型）进行推理，而是希望将数据完全保存在本地。这需要在性能和安全之间找到平衡。尽管公有云拥有丰富的 GPU 资源，且 “时间到洞察”（Time to Insight）至关重要，但数据显示企业更偏好私有云，尤其在部署生成式 AI（GenAI）工作负载时。

2. 数据治理（27%）

与安全问题类似，AI 的数据治理同样强调控制权。企业领导者需要明确掌握数据的内容，并严格监管数据访问权限。例如，当 AI 或 ML 工程师需要从私有云提取原始数据并将其传输至公有云（如 AWS 或 Google Cloud）以微调 AI 模型后再将数据返回私有云时，数据在传输和存储过程中必须加密。此外，私有云与公有云需要通过统一的身份提供商（Identity Provider）实现身份验证与授权。健全的访问控制以及清晰的访问记录和变更记录是强有力的数据治理的基础。

3. 云原生存储（25%）

云原生存储为企业 AI 需求提供了强有力的支持，包括容器化、编排、RESTful API 以及微服务架构。云原生存储基于软件定义和标准化，拥有丰富的开箱即用生态系统。而传统的 SAN（Storage Area Network，存储区域网络）和 NAS（Network-Attached Storage，网络附加存储）技术由于其硬件定义的特性，并不适合云原生环境。

## AI 的入门通道 —— 数据湖仓

研究表明，传统 AI 仍为企业创造着价值。另一个 IT 领导者关注的重点投资领域是数据湖仓架构。回顾调查结果可以发现，高级分析（Advanced Analytics）是最受欢迎的应用场景，而现代数据湖 / 湖仓（Modern Data Lake/Lakehouses）排名第三。

许多高级分析工作负载都基于数据湖 / 湖仓架构构建，使其成为实现更复杂 AI 工作负载的重要入门通道。更重要的是，这些工作负载正在模糊 “高级分析” 的界限，正如 Snowflake、Databricks、Dremio、Starburst、Athena 和 BigQuery 等产品的最新发布所显示的那样。值得注意的是，这些产品无一例外地都构建在对象存储之上。

因此，==绝大多数受访的 IT 高管计划立即利用对象存储构建大规模数据湖仓架构==。

> 构建数据湖仓结构可以通过以下步骤实现：
>
> 1. 选择对象存储服务
>
> 选择一个支持对象存储的云服务提供商，如 AWS S3、Azure Blob Storage 或 Google Cloud Storage。
>
> 2. 设计数据湖架构
> - **原始数据层 (Raw Layer):** 存储未处理的原始数据，保持数据的原始格式。
> - **清洗数据层 (Cleansed Layer):** 存储经过清洗和预处理的数据。
> - **分析数据层 (Analytical Layer):** 存储经过转换和聚合的数据，供分析和建模使用。
>
> 3. 数据摄取
> - 使用 ETL 工具（如 Apache NiFi、AWS Glue）或自定义脚本将数据从源系统导入数据湖。
> - 支持批量和流式数据摄取。
>
>  4. 数据处理和转换
> - 使用分布式计算框架（如 Apache Spark、Hadoop）对数据进行清洗、转换和聚合。
> - 采用数据格式优化存储，如 Parquet、ORC 等，以提高查询性能。
>
>  5. 数据治理和安全
> - 实施数据治理策略，包括数据分类、元数据管理和数据生命周期管理。
> - 配置访问控制和权限管理，使用 IAM 策略、加密和日志审计来确保数据安全。
>
> 6. 数据仓库集成
> - 将数据湖与数据仓库（如 Amazon Redshift、Google BigQuery）集成，支持复杂查询和 BI 工具。
> - 利用 ETL/ELT 流程定期将数据从数据湖加载到数据仓库。
>
> 7. 数据消费
> - 提供多种数据访问方式，支持 SQL 查询、API 访问和数据可视化工具。
> - 通过机器学习平台（如 AWS SageMaker、Azure ML）进行高级分析和建模。
>
> 8. 监控和优化
> - 实施监控机制，跟踪数据摄取、处理和查询性能。
> - 定期优化存储和计算资源，降低成本，提高效率。
>
> 通过以上步骤，可以利用对象存储构建一个灵活、可扩展的数据湖仓结构，有效支持企业的数据分析和决策需求。

## 企业运行云基础设施和对象存储的现状

云是一种操作模式，而非特定位置。通过容器化、编排、RESTful API（如 S3）、微服务和软件定义基础设施等核心支柱，整个技术栈及其上的数据可以实现可移植性。

公有云的基础是对象存储。AWS S3、Azure Blob Storage 和 Google Cloud Storage 等平台的成功便印证了这一点。这些平台的主要存储技术均为对象存储。

因此，当被问及云基础设施的部署情况时，公有云的领先地位并不令人意外。

这一趋势同样适用于新兴的 AI/ML 工作负载。然而，==需要注意的是，无论是公有云还是私有云，都存在大量的混合部署。这要求公有云和私有云基础设施都必须具备云原生特性==。然而，SAN/NAS 或硬件设备技术由于其本质，并不具备真正的云原生特性。

目前，最大的受访者群体（48%）采用了混合部署方式，在公有云和私有云中同时运行 AI/ML 工作负载。这是一个值得持续关注的数据点。经济因素可能会加速这种平衡的转变。==企业对成本的关注正使公有云逐渐变得不适合 AI/ML 的需求，这已推动更多的数据迁回本地（Repatriation）以及对私有云的更广泛使用==。

最后，为了避免将企业的云使用情况简单化，我们还询问了受访者所使用的云数量。结果与其他研究一致，即现代企业通常是多云环境的用户。

## AI 时代存储的挑战、机遇与需求

现代对象存储为企业组织提供了支持多样化应用场景的灵活解决方案，远远超出了过去以归档和备份为主的用途。随着企业对对象存储依赖程度的加深，他们对对象存储功能的期望也不断提高。

研究发现，无论在公有云还是私有云环境中，企业认为对象存储最重要的三大功能是：

- Identity and access management / 身份和访问管理（47%）
- Data life cycle management and tiering / 数据生命周期管理和分层（46%）
- Encryption / 加密（44%）

另一方面，受访者指出本地数据存储基础设施面临的三大挑战是：

- Security concerns / 安全问题（50%）
- High costs / 成本高（43%）
- Data management and integration issues / 数据管理和集成问题（39%）

尽管未进入前三，但性能问题（37%）和扩展性问题（31%）也被视为私有云的主要挑战之一。

除了成本考量（后续会进一步探讨），这些结果揭示了选择存储技术，尤其是对象存储时的三个关键驱动因素：

1. 安全性

不仅需要高水平，还需要简单易用。无论存储架构如何，安全性始终是关键关注点和必要功能。在当今环境中，静态加密和传输加密已成为基本要求，更高水平的安全能力也成为必需条件。与知名身份提供商集成以实现认证和授权，使对象存储能够轻松融入现有数据中心。然而，安全性的一个关键要素是其简单性。复杂性本身就是一个攻击面，系统越复杂，漏洞越多。能够提供简单安全性的对象存储，使企业在更换云提供商或采用新解决方案时，不会对数据安全性造成妥协，同时具备更大的灵活性。

2. 高成本

在选择存储解决方案时，成本仍然是一个重要因素，无论是对象存储还是其他类型的存储。虽然成本并非对象存储的核心价值驱动因素，但它可以在不同解决方案之间起到区分作用，尤其是在比较私有云和公有云时。

数据在成本方面呈现出两面性，这对 IT 领导者来说并不陌生。首先，==私有云相较于公有云具有更好的经济性==。

生成式 AI 的兴起已导致公有云成本急剧攀升。近 40% 的受访者表示，他们 “非常” 或 “极为” 担心在云中运行 AI/ML 工作负载的成本，另外 29% 的受访者也表示对此有一定的担忧。随着规模的扩大，访问公有云中的数据，尤其是用于训练和微调 AI 模型的数据，变得越来越困难且成本高昂。调查显示，云支出同比增长了 30%，Tangoe 的报告还表明，72% 的 IT 领导者表示云支出已经变得不可控。

企业希望避免重蹈覆辙，不想再次因为云存储成本飙升而陷入困境 —— 这正是 Cloud FinOps（云财务运维）行业诞生的原因。随着 AI 工作负载导致数据存储和计算成本的激增，公有云正逐渐失去其可行性，这推动了更多的私有云使用甚至数据回迁。虽然公有云拥有大量 GPU，适合用于小规模的实验和学习，但在生产环境中，企业更需要控制和简化。

其次，在私有云中，硬件设备模型（appliance model）并不具有成本优势。43% 的受访者将成本问题列为私有云对象存储方案的第二大挑战。企业对硬件设备模型感到厌倦，因为它会导致厂商锁定并限制选择灵活性。相反，企业希望能够使用智能软件、简单硬件，并且价格能够与其部署需求相匹配。

软件定义存储（SDS）提供了企业所需的灵活性、控制力和杠杆作用 —— 这也是它成为当前及未来首选架构的原因。然而，由于成本优势，许多企业正在选择将某些工作负载回迁到私有云基础设施。

> 软件定义存储（Software-Defined Storage，SDS）是一种数据存储管理的方式，通过软件来控制和管理存储硬件资源。SDS 的主要特征包括：
>
> 1. **硬件抽象**：将存储功能从底层硬件中分离，使得不同品牌和类型的硬件可以统一管理。
> 2. **灵活性和可扩展性**：可以根据需求动态调整存储资源，方便扩展和缩减。
> 3. **自动化和编排**：通过自动化工具和编排技术简化存储管理，提高效率。
> 4. **成本效益**：利用通用硬件，降低采购和维护成本。
> 5. **集中管理**：通过一个统一的界面对所有存储资源进行管理，简化操作。
>
> SDS 适用于需要高效管理大量数据的环境，如云计算和大数据应用。

3. 数据管理与规模化性能需求

如前所述，==云是一种操作模式，而非特定位置。与其相适应的存储即为云原生存储（Cloud-native Storage）。不符合这一特性的存储通常即为硬件设备==。

四分之一的 IT 领导者表示，==他们在管理和整合私有云对象存储时遇到了困难。其原因或在于他们采用了硬件设备模型。硬件设备无法容器化，本质上并非云原生==。

基于硬件的存储系统作为一种固定的硬件中心化解决方案，固有地受到其物理限制和静态架构的约束。它缺乏与容器化应用程序和现代云原生工作流无缝集成的灵活性。硬件设备通常需要手动扩展，这迫使企业过度配置存储，导致效率低下和成本增加。此外，硬件设备依赖于专有硬件，使得它们不适用于需要灵活性、可扩展性和分布式操作的环境。

相比之下，软件定义的云原生对象存储体现了云操作模型的原则。它与特定硬件解耦，可以在任何基础设施上部署，无论是本地、公有云中，还是在混合部署环境中。云原生对象存储能够弹性扩展，根据需求调整容量，并与 Kubernetes 等编排工具无缝集成。该模型还利用 API 进行自动化和可编程性，帮助 IT 团队高效管理大规模的分布式数据环境。

这些因素推动了存储技术选择标准的转变。当我们询问 IT 领导者如何排序选择对象存储（公有云或私有云）时，他们提供了以下反馈：

1. Security / 安全性
2. Performance / 表现
3. Cost / 成本
4. Scalability / 可扩展性
5. Multi-Cloud / 多云
6. Simplicity / 简易性

## 大规模数据存储的运营：何为、为何、如何

操作细节非常重要，我们向受访者请求了一些关于其存储系统架构、背后硬件以及相关团队的数据。以下是部分数据。

可扩展性一直是推动对象存储崛起的关键因素之一。如今，随着 AI 和分析对存储和检索大量数据的灵活性需求不断增加，企业对性能和规模的要求比以往任何时候都更高。在各种基础设施中，对象存储提供了容量、性能和简便性，使企业数据能够达到新的高度。

我们的研究发现，近 20% 的云端对象存储部署规模至少为 10PB。在这个规模上，大多数技术开始出现裂痕。这是传统 API（如 POSIX）变得过于冗长或第三方元数据数据库出现故障的时刻。更重要的是，市场上的每个预测都表明，企业数据正在以超过 60% 的年复合增长率（CAGR）增长。

这意味着典型的对象存储集群将增大规模。这是由于无结构数据的持续增长（预计年增长率为 55%-65%），这些数据用于训练传统 AI 和生成式 AI 模型，并且在各类应用中的对象存储使用也在增加。云对象存储市场也有望从 2023 年的 65 亿美元增长到 2031 年的 180 亿美元，几乎是其三倍，显示出更广泛的采用和更大规模的部署。

对象的大小也很重要。能够在小型对象上良好运行是顶级对象存储的一个显著特点。尽管如此，大多数对象的大小都在 MB 级别。

企业级对象存储中的典型对象大小：

- 小于 1 MB（30%）
- 1 至 10 MB（29%）
- 大于 10 MB（29%）
- 未知（12%）

网络是一个动态变化的领域，AI 无疑处于这一变化的推动之中。几年前被认为极为快速的 100GbE 网络如今已成为基础设施标准。接近一半的受访者（43%）表示，他们组织中的对象存储集群的典型网络速度为 100GbE 或更快。这些高速网络的出现与高吞吐量、高性能对象存储的采用趋势相一致。传统的对象存储应用（如归档和备份）不需要如此高的带宽，但像灾难恢复这样的工作负载（41% 的受访者表示使用对象存储进行灾难恢复）确实需要这种性能。

对速度的需求也体现在驱动器类型上。现在，我们生活在一个 NVMe/SSD 的世界中，这反映了它们相较于 HDD 在性能和密度方面的优势。

在未来三年，NVMe 预计将成为最大的增长领域，在企业中的数据份额预计将增加 3 个百分点。

统计的存储平台中存储的数据比例如下：

- SATA HDD（33%）
- SATA SSD（36%）
- NVMe SSD（29%）
- Other（2%）

未来三年，NVMe 预计将成为增长最快的领域，在企业中的数据份额预计将增加 3 个百分点。

存储团队的动态是一个值得关注的领域。尽管 IT 运营 / 基础设施显然是主导力量，但它绝不是唯一参与存储管理的团队。许多团队都在参与其中，这也符合当前数据几乎是每个组织核心资产的事实。

话虽如此，DevOps、开发和数据团队显然都在其中扮演着重要角色。

说到团队合作，管理 PB 级数据需要一个完整的团队。在受访组织中，超过三分之二的受访者表示，管理这种规模的数据至少需要四名或更多的全职员工。

## 总结：一个以 AI 为中心、以对象存储为主导的世界

到 2024 年，大多数企业的数据已经存储在对象存储中，这一趋势预计将持续增长。对象存储主导地位的两个关键原因很明确：

对象存储不仅支持 AI，还推动 AI 的发展，满足安全需求，解决成本和可扩展性问题，并支持跨工作负载的高性能。

企业在数据存储上优先考虑大规模性能，可能比其他任何因素都更为重要。他们希望获得云原生世界中传统 SAN/NAS 技术难以提供的灵活性和简便性。

不断攀升的公有云成本不可持续 —— 但显然，成本在选择工作负载和可扩展性时不是最重要的因素。我们可以推测，在成本和功能之间做出选择时，企业将更加注重后者。在所有可用的解决方案中，运行在私有云上的软件定义存储最有可能让企业获得所需的一切。
